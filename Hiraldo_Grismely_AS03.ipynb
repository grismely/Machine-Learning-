{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be803785",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "# Author: Grismely M. Hiraldo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ab4cf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3888098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Iris data set\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "Xzeros0 = (0. * X) + .2\n",
    "Xzeros1 = (0. * X) \n",
    "Xzeros2 = (0. * X) - .2\n",
    "x_min, x_max = X.min() - 0.5, X.max() + 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48e78eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 o Setosa red pink\n",
      "1 x Versicolor blue lightblue\n",
      "2 * Virginica green lightgreen\n"
     ]
    }
   ],
   "source": [
    "# get Iris classifications\n",
    "\n",
    "IC = np.unique(Y)\n",
    "IrisC = ('Setosa','Versicolor','Virginica')\n",
    "pltC = ('red', 'blue', 'green')\n",
    "pltCback = ('pink', 'lightblue','lightgreen')\n",
    "pltM = ('o', 'x', '*')\n",
    "for i in range(0,3):\n",
    "    print (IC[i],pltM[i],IrisC[i],pltC[i],pltCback[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa8013d",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent using the modified-Huber loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a9c100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.7733333333333333\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,1])           # this array contains the features to be considered ( AB features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "# clf = Perceptron(tol=1e-4, random_state=0)\n",
    "clf = SGDClassifier(tol=1e-4, random_state=0)\n",
    "\n",
    "clf.fit(XX,YY)\n",
    "\n",
    "print('\\nScore: ',clf.score(XX,YY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04317e0a",
   "metadata": {},
   "source": [
    "The accuracy of the model on the subset of the data used for this pair is only .773, which can be intereppted as the model being semi accurate on this particular combination of features but because of previous experience (assignment 1) with this model I anticipate to find more a more accurate model on the data even on all the subet of feature combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d2de98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.8733333333333333\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,2])           # this array contains the features to be considered ( AC features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "# clf = Perceptron(tol=1e-4, random_state=0)\n",
    "clf = SGDClassifier(tol=1e-4, random_state=0)\n",
    "\n",
    "clf.fit(XX,YY)\n",
    "\n",
    "print('\\nScore: ',clf.score(XX,YY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ffbc9b",
   "metadata": {},
   "source": [
    "The model has a higher accuracy on this subset of features by 10% this could be because its been observed previously that features can affect accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f3651c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.94\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,3])           # this array contains the features to be considered ( AD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "# clf = Perceptron(tol=1e-4, random_state=0)\n",
    "clf = SGDClassifier(tol=1e-4, random_state=0)\n",
    "\n",
    "clf.fit(XX,YY)\n",
    "\n",
    "print('\\nScore: ',clf.score(XX,YY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f01eaea",
   "metadata": {},
   "source": [
    "The highest score thus far for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7a8b52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.8866666666666667\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([1,2])           # this array contains the features to be considered ( BC features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "# clf = Perceptron(tol=1e-4, random_state=0)\n",
    "clf = SGDClassifier(tol=1e-4, random_state=0)\n",
    "\n",
    "clf.fit(XX,YY)\n",
    "\n",
    "print('\\nScore: ',clf.score(XX,YY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd9423",
   "metadata": {},
   "source": [
    "A relavtiely high score of accuracy for the model again not 100% but high enough that we cannot cross out the model as bad or inaccurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9ac0760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.8933333333333333\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([1,3])           # this array contains the features to be considered ( BD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "# clf = Perceptron(tol=1e-4, random_state=0)\n",
    "clf = SGDClassifier(tol=1e-4, random_state=0)\n",
    "\n",
    "clf.fit(XX,YY)\n",
    "\n",
    "print('\\nScore: ',clf.score(XX,YY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf139bca",
   "metadata": {},
   "source": [
    "Starting to see more consistency in the scores for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c9b8a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.96\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([2,3])           # this array contains the features to be considered ( CD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "# clf = Perceptron(tol=1e-4, random_state=0)\n",
    "clf = SGDClassifier(tol=1e-4, random_state=0)\n",
    "\n",
    "clf.fit(XX,YY)\n",
    "\n",
    "print('\\nScore: ',clf.score(XX,YY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8e2f24",
   "metadata": {},
   "source": [
    "The highest accuracy score the model had. Overall, the score was about 0.885 or 88.5 with a low outlier of 0.77 and some high 90s. I think it can be said that the model was decent it could still be considered accurate as it did have, with the exception of the .77, mid 90s and high 80 scores because the scores did flux I would say that while the model was decent we can say confidently that it is probably not the best model to train for our data and we could find better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3565fa03",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c439d7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,1])           # this array contains the features to be considered ( AB features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "# clf = Perceptron(tol=1e-4, random_state=0)\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(XX,YY)\n",
    "\n",
    "print('\\nScore: ',log_reg.score(XX,YY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f2ae6c",
   "metadata": {},
   "source": [
    "The accuracy of the model on the subset of the data used for this pair is 0.96 it is nearly 100% accurate which indicates that the model was trained well over this subset and is/will produce accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb6f43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.96\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,2])           # this array contains the features to be considered ( AC features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "# clf = Perceptron(tol=1e-4, random_state=0)\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(XX,YY)\n",
    "\n",
    "print('\\nScore: ',log_reg.score(XX,YY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc3a0b",
   "metadata": {},
   "source": [
    "Same accuracy score as the last subset, there already seems to be more consistency with the logistic regression model which I think is very befitting because even a general log function is not linear and tends to encomposs and show trends for more irregular data while linear functions can often leave out clusters of data like outliers. I think this model would benefit from plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4cb4777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.96\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,3])           # this array contains the features to be considered ( AD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "# clf = Perceptron(tol=1e-4, random_state=0)\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(XX,YY)\n",
    "\n",
    "print('\\nScore: ',log_reg.score(XX,YY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99824b63",
   "metadata": {},
   "source": [
    "The model continues to show consitnecy and accuracy with a strong score of 96%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ccf5656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([1,2])           # this array contains the features to be considered ( BC features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "# clf = Perceptron(tol=1e-4, random_state=0)\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(XX,YY)\n",
    "\n",
    "print('\\nScore: ',log_reg.score(XX,YY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaf4c72",
   "metadata": {},
   "source": [
    "The model continues to show consitnecy and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1c25394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.96\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([1,3])           # this array contains the features to be considered ( BD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "# clf = Perceptron(tol=1e-4, random_state=0)\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(XX,YY)\n",
    "\n",
    "print('\\nScore: ',log_reg.score(XX,YY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f58239",
   "metadata": {},
   "source": [
    "The model continues to show consitnecy and accuracy with a another score of 96%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e44761a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([2,3])           # this array contains the features to be considered (CD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "# clf = Perceptron(tol=1e-4, random_state=0)\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(XX,YY)\n",
    "\n",
    "print('\\nScore: ',log_reg.score(XX,YY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad91ee67",
   "metadata": {},
   "source": [
    "Overall, it seems that logistic regression was trained well over the data and overall is a good fit. Although the model did not produce an 100% or 1.0 score there was consistency in the accuracy scores as they all were approxiamantly 96 with the exception of one that was 95, and the scores themselves are also quite high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc36fc01",
   "metadata": {},
   "source": [
    "# Support Vector Machine - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8dd8af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.82\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,1])           # this array contains the features to be considered (AB features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "linear_svc = svm.SVC(kernel='linear')\n",
    "linear_svc.fit(XX,YY);\n",
    "print('\\nScore: ',linear_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3db68d3",
   "metadata": {},
   "source": [
    "The linear SVM model over the data had a score of 0.82, a pretty good score but it should be noted that sepal length and width the pair the model is used on for this set has been observed to usually result in lower accuracy in the past, this may just be a result of the model not training well over these features but if it continues to occur from the previous assignment to this one it may be that there is a very large disperaity in the data or that it is vastly scattered so the model is training with many outliters and very little patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1fbddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,2])           # this array contains the features to be considered (AC features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear')\n",
    "linear_svc.fit(XX,YY);\n",
    "print('\\nScore: ',linear_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03828b9",
   "metadata": {},
   "source": [
    "The model has 95% accuracy over this pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4da49d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.96\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,3])           # this array contains the features to be considered (AD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear')\n",
    "linear_svc.fit(XX,YY);\n",
    "print('\\nScore: ',linear_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e75db9",
   "metadata": {},
   "source": [
    "There is some consistency between this pair and the previous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4cb7b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.96\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([1,2])           # this array contains the features to be considered (BC features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear')\n",
    "linear_svc.fit(XX,YY);\n",
    "print('\\nScore: ',linear_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b0c092",
   "metadata": {},
   "source": [
    "The model is showing consistency and accuracy with a recuring score of 96%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "436190ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.96\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([1,3])           # this array contains the features to be considered (BD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear')\n",
    "linear_svc.fit(XX,YY);\n",
    "print('\\nScore: ',linear_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9279c1",
   "metadata": {},
   "source": [
    "The model is showing consistency and accuracy with a recuring score of 96%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48dd4b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([2,3])           # this array contains the features to be considered (CD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear')\n",
    "linear_svc.fit(XX,YY);\n",
    "print('\\nScore: ',linear_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4330294a",
   "metadata": {},
   "source": [
    "This model also seemed to have trained well over the data with just one outlier of 88% which is still a decently high score. This was honestly to my surprise as mentioned previously sometimes linear functions and models can exclude clusters of data. I think we could also cofnidently say this is a good model for our data as it showed accuracy and conisstency through all subsets of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e5c38d",
   "metadata": {},
   "source": [
    "# Support Vector Machine - Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5034b153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.8133333333333334\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,1])           # this array contains the features to be considered (AB features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "poly_svc = svm.SVC(kernel='poly')\n",
    "poly_svc.fit(XX,YY);\n",
    "print('\\nScore: ',poly_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a2571",
   "metadata": {},
   "source": [
    "The point made about sepal width and length seems to hold true across all models, although the score is still pretty good it is always the lowest score between all six subsets, this tells me that one of my two predictions about the data may be true as we expose the data set to more models it seems more and more true that the models are underfitting the subset pair of sepal width and length or that the data itself may have discrepenscies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29d59bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.96\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,2])           # this array contains the features to be considered (AC features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "poly_svc = svm.SVC(kernel='poly')\n",
    "poly_svc.fit(XX,YY);\n",
    "print('\\nScore: ',poly_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a69b3",
   "metadata": {},
   "source": [
    "The model has 96% accuracy over this pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11a01dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,3])           # this array contains the features to be considered (AD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "poly_svc = svm.SVC(kernel='poly')\n",
    "poly_svc.fit(XX,YY);\n",
    "print('\\nScore: ',poly_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29faa014",
   "metadata": {},
   "source": [
    "The model has 95% accuracy over this pair, after our initial pair we are starting to see consistency in the scores just as the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c46588a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([1,2])           # this array contains the features to be considered (BC features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "poly_svc = svm.SVC(kernel='poly')\n",
    "poly_svc.fit(XX,YY);\n",
    "print('\\nScore: ',poly_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9952d07",
   "metadata": {},
   "source": [
    "The model has 95% accuracy over this pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "196679ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.96\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([1,3])           # this array contains the features to be considered (BD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "poly_svc = svm.SVC(kernel='poly')\n",
    "poly_svc.fit(XX,YY);\n",
    "print('\\nScore: ',poly_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16f836",
   "metadata": {},
   "source": [
    "The model has 96% accuracy over this pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57155ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([2,3])           # this array contains the features to be considered (CD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "poly_svc = svm.SVC(kernel='poly')\n",
    "poly_svc.fit(XX,YY);\n",
    "print('\\nScore: ',poly_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc7c73",
   "metadata": {},
   "source": [
    "The polynomial SVM model was very similar to the linear SVM model over our data, the first subset (sepal width, sepal length) has the lowest accuracy score for both and after there it assumes more consistency and accuracy with a recurging score of 95 or 96 just as the previous model did. Since this is the second use of SVM models we could potentially say with the next model as proof that the way the SVM model trains over sepal width and length is resulting in underfitting and may be why in both SVM models that subset has the lowest accuracy despite the model showing consistency and accuracy over the rest of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b82f4bd",
   "metadata": {},
   "source": [
    "# Support Vector Machine - RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3d77af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.82\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,1])           # this array contains the features to be considered (AB features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "rbf_svc = svm.SVC(kernel='rbf')\n",
    "rbf_svc.fit(XX,YY);\n",
    "print('\\nScore: ',rbf_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f93be",
   "metadata": {},
   "source": [
    "The accuracy of the model over this subset is 82% this supports our previous claims that the SVM models could be underfitting this particular subset as for the third time this subset has the lowest accuracy score, unlike the logistic regression that had no outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95140df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.96\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,2])           # this array contains the features to be considered (AC features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "rbf_svc = svm.SVC(kernel='rbf')\n",
    "rbf_svc.fit(XX,YY);\n",
    "print('\\nScore: ',rbf_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1717717b",
   "metadata": {},
   "source": [
    "The model has 96% accuracy over this pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03ccaeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.96\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([0,3])           # this array contains the features to be considered (AD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "rbf_svc = svm.SVC(kernel='rbf')\n",
    "rbf_svc.fit(XX,YY);\n",
    "print('\\nScore: ',rbf_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936cf0b8",
   "metadata": {},
   "source": [
    "The model has 95% accuracy over this pair, second occurance of the score for this model, we will now see a consitency in it just like the models before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1b2ca03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([1,2])           # this array contains the features to be considered (BC features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "rbf_svc = svm.SVC(kernel='rbf')\n",
    "rbf_svc.fit(XX,YY);\n",
    "print('\\nScore: ',rbf_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab65ab2d",
   "metadata": {},
   "source": [
    "The model has 95% accuracy over this pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02f4b1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.96\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([1,3])           # this array contains the features to be considered (BD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "rbf_svc = svm.SVC(kernel='rbf')\n",
    "rbf_svc.fit(XX,YY);\n",
    "print('\\nScore: ',rbf_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a10104e",
   "metadata": {},
   "source": [
    "The model has 96% accuracy over this pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da23b76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score:  0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "# choose the classes and features to be included in the model\n",
    "\n",
    "cdx = np.array([0,1,2])             # this array contains the classes to be considered (3 classes)\n",
    "fdx = np.array([2,3])           # this array contains the features to be considered (CD features)\n",
    "\n",
    "nC = len(cdx)\n",
    "nF = len(fdx)\n",
    "\n",
    "# build the XX and YY arrays\n",
    "# these arrays contain the samples in the classes specified in cdx and include the features specified in fdx\n",
    "\n",
    "i = 0\n",
    "numY = 0\n",
    "for i in range(len(Y)):\n",
    "    for j in range(nC):\n",
    "        if Y[i] == IC[cdx[j]]:\n",
    "            numY += 1\n",
    "\n",
    "YY = np.zeros((numY))\n",
    "XX = np.zeros((numY,nF))\n",
    "if (len(fdx) == 1):\n",
    "    XXzeros0 = (0. * XX) + .2\n",
    "    XXzeros1 = (0. * XX) \n",
    "    XXzeros2 = (0. * XX) - .2\n",
    "\n",
    "j = 0\n",
    "for i in range(len(Y)):\n",
    "    for k in range(nC):\n",
    "        if Y[i] == IC[cdx[k]]:        \n",
    "            YY[j] = IC[cdx[k]]\n",
    "            for m in range(nF):\n",
    "                XX[j,m] = X[i,fdx[m]] \n",
    "            j += 1\n",
    "            \n",
    "# fit the model\n",
    "\n",
    "rbf_svc = svm.SVC(kernel='rbf')\n",
    "rbf_svc.fit(XX,YY);\n",
    "print('\\nScore: ',rbf_svc.score(XX,YY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd25fbbc",
   "metadata": {},
   "source": [
    "Not unlike the other SVM models after the first subset there was more consistency and accuracy in the 95-96% range but unlike its predecessors the rbf model did result in more 95% scores which is not a drastic difference but should still be noted so that we may properly critique and compare our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1037549e",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd507344",
   "metadata": {},
   "source": [
    "It was very interesting and refreshing to use different models over familar data. It can be said, naturally, that some models were trained better over the data and were a better or more accuracte fit. It was also interesting to see previous notes and assumptions I had made in our last assignment hold true or be brought up again. I will use this to open my discussion about the models used in this assignment. Once again there seems to be something off, seemingly underfitting with the subset data pair (Sepal length and Sepal width) across all models except logistic regression. The models that seem to be underfited over this subset do not have low accuracy scores however their lowest accuracy scores all are from this particular pair. This leads me to presume there is soemthing off in how the model was trained over it or that there may be some discrepency in the actual data but the later seems more possible. Moving on, the first model, the Stochastic gradient descent using the modified-Huber loss function, performed as expected. Like it did previously it was good but not great there were certain scores that told us that there was a better fit for our data. The Logistic Regression Model I believed performed the best and is the best fit for our data, it was consistent and accurate and the only exception to our sepal length and width dilemma. Although it did not result in a score of 100% it approach it at 96% over ever subset pair, the only model to do so. The SVM models are performed similarly, the first subset pair always resulted in a mid 80s accuracy score and then there would be recuring 96s and 95s after. Overall, I don't think we can rule any model as bad or truly inaccurate they all performed pretty similar, Logistic Regression can be ruled as simply the better fit because its was consitent through all the subsets (6/6) while most were (5/6). The last thing I think it is important to make note of is that none of our models resutled in 100% over our data.I would not say this calls for concer because I speculate that it stems from the fact our models were only being trained over subset pairs and not all four features. I tested this by adding all four features (0,1,2,3) to three of our models and the accuracy scores went from 96 to 98. So despite no 100% accuracy on our models they are still good models and I would be interested to see how all the models do with the four features included."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
